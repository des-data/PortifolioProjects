
from bs4 import BeautifulSoup
import requests

url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'

page=requests.get(url)

soup=BeautifulSoup(page.text,'html')

print(soup.prettify())

soup.find('table',class_='wikitable sortable')

table = soup.find_all('table')[0]
print(table)

world_titles = table.find_all('th') #this will give us the columns of the table we are interested in. 
#If we do soup.find_all('th') we end up with all the column headers for all the tables

world_titles

world_table_titles = [title.text.strip() for title in world_titles]
print(world_table_titles)

#import pandas to have the data in columns
import pandas as pd

df = pd.DataFrame(columns = world_table_titles)
df

column_data = table.find_all('tr')

for row in column_data:
    row_data = row.find_all('td')
    individual_row_data = [data.text.strip() for data in row_data]
    print(individual_row_data)

for row in column_data[1:]: #this [1:] helps specify where the data should start to avoid the blank row
    row_data = row.find_all('td')
    individual_row_data = [data.text.strip() for data in row_data]
    #print(individual_row_data)
    
    length = len(df)
    df.loc[length] = individual_row_data # append each data row accordingly

df

df.to_csv(r'C:\Users\Administrator\Documents\Learning Area\Data Camp by Alex the Analyst\Python Webscraping\Companies.csv',index = False)
